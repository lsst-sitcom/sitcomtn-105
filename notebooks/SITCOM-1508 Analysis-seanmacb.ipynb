{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1d8296-a786-4655-9d70-b6b2a21f6e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from astropy.time import Time\n",
    "from lsst.summit.utils.efdUtils import makeEfdClient, getEfdData\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from lsst_efd_client import EfdClient\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import os\n",
    "# %load_ext lab_black # enable the Black extension for auto formatting\n",
    "# %load_ext autoreload # enable auto-reload. Useful if we want to have a python module to import from\n",
    "# %autoreload 2 # powering up autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b152cbca-b1d9-47ea-aa5b-a62067f760a6",
   "metadata": {},
   "source": [
    "# Compare TMA balancing data from previous events with the next events\n",
    "\n",
    "We are getting ready to balance the telescope twice in the next weeks. First, we will balance the telescope with ComCam and M2 Glass. The M2 Glass and M2 Surrogate have similar weights, with a small difference. We expect the torques applied by the elevation drives will be very close to the previous balancing event(s). A couple of weeks later, we will repeat the procedure with ComCam, M2 Glass, and M1M3 Glass. The M1M3 Glass and M1M3 Cell assembly is much heavier than the M1M3 Mass Simulator (yellow cross) and hundreds of kilograms heavier than the M1M3 Surrogate and M1M3 Cell configuration. This procedure will be much more delicate due to the size and mass of the mirror. \n",
    "\n",
    "We want to establish a baseline before we start the procedure, and we need someone to review the data to determine whether we can proceed quickly. \n",
    "\n",
    "The links below point to old night logs that might contain useful information. Feel free to unlink them if they are not useful. \n",
    "\n",
    "Here is an approximate timeline of different integration phases where we needed to re-balance the telescope. \n",
    "We do not necessarily need the whole process. We need the torques once the telescope is already balanced as a baseline.\n",
    "\n",
    "May to Aug 2023 - M1M3 Surrogate and M1M3 Cell on the TMA\n",
    "\n",
    "Nov 2023 to Jan 2024 - M1M3 Surrogate and Cell, M2 Surrogate and Cell on the TMA\n",
    "\n",
    "Feb to Apr 2024 - M2 Surrogate and Cell on the TMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6703e569-b1b5-4774-abce-002116893a9b",
   "metadata": {},
   "source": [
    "## A few top-level imports (that I really should put in a library at some point...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6efe50a-2c74-4de8-97c5-295507edc33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def query_bump_logs_in_chunks(\n",
    "    start_date, end_date, client_name=\"\", chunk_size_days=3,topic_name=\"lsst.sal.MTM1M3.logevent_logMessage\",fields=[\"message\"]\n",
    "):\n",
    "    \"\"\"\n",
    "    Queries the log messages related to bump tests from the EFD in chunks.\n",
    "\n",
    "    Args:\n",
    "        start_date (str): Start date of the query in ISO format (YYYY-MM-DD).\n",
    "        \n",
    "        end_date (str): End date of the query in ISO format (YYYY-MM-DD).\n",
    "        \n",
    "        client_name (str, optional): Name of the EFD client. Defaults to \"\".\n",
    "        \n",
    "        chunk_size_days (int, optional): Number of days per chunk. Defaults to 3.\n",
    "\n",
    "        topic_name (str, optional): SAL topic name to be queried by the client. Defaults to lsst.sal.MTM1M3.logevent_logMessage.\n",
    "\n",
    "        fields (list[str], optional): Fields to be queried by the client. Defaults to [\"message\"].\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Concatenated DataFrame containing the queried log messages.\n",
    "    \"\"\"\n",
    "\n",
    "    client = makeClient(client_name)\n",
    "\n",
    "    # Convert start and end dates to datetime objects\n",
    "    start = datetime.fromisoformat(start_date)\n",
    "    end = datetime.fromisoformat(end_date)\n",
    "\n",
    "    # Initialize an empty DataFrame to store concatenated results\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    current_start = start\n",
    "    while current_start < end:\n",
    "        current_end = min(current_start + timedelta(days=chunk_size_days), end)\n",
    "        try:\n",
    "            # Query the data for the current chunk\n",
    "            chunk_data = await client.select_time_series(\n",
    "                topic_name=topic_name,\n",
    "                fields=fields,\n",
    "                start=Time(current_start.isoformat(), format=\"isot\", scale=\"utc\"),\n",
    "                end=Time(current_end.isoformat(), format=\"isot\", scale=\"utc\"),\n",
    "            )\n",
    "            # Concatenate the chunk data to the main DataFrame\n",
    "            all_data = pd.concat([all_data, chunk_data], ignore_index=False)\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"Error querying data from {current_start.isoformat()} to {current_end.isoformat()}: {e}\"\n",
    "            )\n",
    "            continue  # Optionally, continue to the next chunk\n",
    "\n",
    "        # Move to the next chunk\n",
    "        current_start = current_end\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def makeClient(client_name):\n",
    "        # Create the client based on client_name\n",
    "    if client_name == \"summit_efd\":\n",
    "        return makeEfdClient(\"summit_efd\")\n",
    "    elif client_name == \"usdf_efd\":\n",
    "        return makeEfdClient(\"usdf_efd\")\n",
    "    elif client_name == \"idf_efd\":\n",
    "        return makeEfdClient(\"idf_efd\")\n",
    "    else:\n",
    "        return makeEfdClient()  # Default client\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# begin = \"2023-11-13T01:00\"\n",
    "# end = \"2023-12-21T01:00\"\n",
    "# bump_logs = await query_bump_logs_in_chunks(begin, end, client_name='')\n",
    "\n",
    "def showAndClear():\n",
    "    plt.show()\n",
    "    # Clear the current axes.\n",
    "    plt.cla() \n",
    "    # Clear the current figure.\n",
    "    plt.clf() \n",
    "    # Closes all the figure windows.\n",
    "    plt.close('all')   \n",
    "    plt.close(fig)\n",
    "    \n",
    "    return\n",
    "\n",
    "async def getDataFrame(client,starts,ends,topic,verbose=True,fields=None):\n",
    "    \n",
    "    all_data = pd.DataFrame()\n",
    "    for start,end in zip(starts,ends):\n",
    "        if verbose:\n",
    "            print(r\"Starting query for time range {} - {}\".format(start,end),end=\" . . . \")\n",
    "        if fields != None:\n",
    "            df_bump = await client.select_time_series(topic,fields, Time(start), Time(end))\n",
    "        else:\n",
    "            df_bump = await client.select_time_series(topic,\"*\", Time(start), Time(end))\n",
    "        \n",
    "        all_data = pd.concat([all_data, df_bump], ignore_index=False)\n",
    "\n",
    "        del df_bump\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Finished\")\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "def makeDateRange(startPoint,endPoint,step=np.timedelta64(1, 'D')):\n",
    "    starts = np.arange(startPoint,endPoint,step=step)\n",
    "    ends = starts + np.timedelta64(1, 'D')\n",
    "    return starts,ends\n",
    "\n",
    "def fitGaussian(data,ax):\n",
    "    mu, std = norm.fit(data) \n",
    "    \n",
    "    xmin, xmax = ax.get_xlim()\n",
    "    x = np.linspace(np.floor(xmin), np.ceil(xmax), int(10E4))\n",
    "    p = norm.pdf(x, mu, std)\n",
    "\n",
    "    return mu,std,p,x,xmin,xmax\n",
    "\n",
    "def getFWHM_from_gaussian(sigma):\n",
    "    return 2*np.sqrt(np.log(2)*2)*sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03d0b26-b8ac-48d4-a8b3-9d95eabd715c",
   "metadata": {},
   "source": [
    "### Setting up the sub-directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554a656d-6381-4eff-b65b-a349ad40ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()\n",
    "figure_dir,data_dir = base_dir+\"/SITCOM-1508-plots\",base_dir+\"/SITCOM-1508-data\"\n",
    "for pathname in [figure_dir,data_dir]:\n",
    "    if not os.path.isdir(pathname):\n",
    "        os.mkdir(pathname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cc3ed1-f237-4a3d-a1e5-4de3bf5914d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbatim = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15a017c-5888-4fda-adf8-f8343e5c62c3",
   "metadata": {},
   "source": [
    "## Get all topics, so we can take a look at what is here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdcf667-237e-4c82-b865-f95b576f9a26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client = makeClient(\"usdf_efd\")\n",
    "\n",
    "a = await client.get_topics()\n",
    "\n",
    "if verbatim:\n",
    "    for entry in a:\n",
    "        if entry.__contains__(\"lsst.sal.MTMount\"):\n",
    "            print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90eb986-24e0-4f1b-853c-d92c762cb85d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b = await client.get_fields(\"lsst.sal.MTMount.elevation\")\n",
    "\n",
    "if verbatim:\n",
    "    for entry in b:\n",
    "        print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53b605d-389b-4872-a8bd-ddf677ec8db9",
   "metadata": {},
   "source": [
    "### M1M3 Surrogate and M1M3 Cell on the TMA - May 2023-Aug 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d2d2b0-7316-412d-bc01-81f9f6a44905",
   "metadata": {},
   "outputs": [],
   "source": [
    "startPoint = np.datetime64(\"2023-05-20T12:00:00\")\n",
    "endPoint = np.datetime64(\"2023-06-30T12:00:00\")\n",
    "starts,ends = makeDateRange(startPoint,endPoint)\n",
    "\n",
    "topic_az = \"lsst.sal.MTMount.azimuth\"\n",
    "fields_az = ['actualTorque']\n",
    "\n",
    "topic_el = \"lsst.sal.MTMount.elevation\"\n",
    "fields_el = [\"actualPosition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2853b562-239a-4cbc-a1a0-b0c6302573eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data_az = await getDataFrame(client,starts,ends,topic_az,fields=fields_az,verbose=False)\n",
    "all_data_el = await getDataFrame(client,starts,ends,topic_el,fields=fields_el,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd813e87-625c-4e35-b6ad-e3cd92b8775a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061656a4-9f96-422d-9946-37ca362bfea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "booArray = np.diff(all_data_el[\"actualPosition\"],prepend=1) == 0\n",
    "timArray = all_data_el.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27082ad8-5dd7-443c-8006-1f53a83879e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getMaskedTimeBounds(boolArray,timeArray):\n",
    "    '''\n",
    "    A function to find the time periods of constant acceleration\n",
    "    '''\n",
    "    \n",
    "    startEntry=True\n",
    "    starts,ends = [],[]\n",
    "    previous_time_entry = timeArray[0]\n",
    "    \n",
    "    for boolEntry,timeEntry in zip(boolArray,timeArray):\n",
    "        if boolEntry and startEntry and not previous_bool_entry:\n",
    "            starts.append(timeEntry)\n",
    "            startEntry=False\n",
    "            # print(\"appending to start\")\n",
    "        elif not boolEntry and not startEntry and previous_bool_entry:\n",
    "            ends.append(previous_time_entry)\n",
    "            startEntry=True\n",
    "            # print(\"appending to end\")\n",
    "        previous_time_entry = timeEntry\n",
    "        previous_bool_entry = boolEntry\n",
    "    return starts, ends\n",
    "            \n",
    "constant_starts,constant_ends = getMaskedTimeBounds(booArray,timArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2aa4e0-7050-4dcb-abaa-3c4bca8a7677",
   "metadata": {},
   "outputs": [],
   "source": [
    "lolim,uplim = pd.Timestamp(\"2023-05-29\").tz_localize(\"UTC\"),pd.Timestamp(\"2023-06-03\").tz_localize(\"UTC\")\n",
    "limited_data = all_data_az.loc[lolim:uplim]\n",
    "lolim,uplim = lolim.tz_localize(None),uplim.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26766ffb-5bd0-42f2-b197-af43eee28bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=[10,6],sharex=True)\n",
    "axs[0].plot(limited_data.index,limited_data)\n",
    "axs[1].hist(limited_data, bins=90, facecolor = '#2ab0ff', edgecolor='#169acf', linewidth=0.5)\n",
    "mu,std,p,x,xmin,xmax = fitGaussian(limited_data,axs[1])\n",
    "axs[1].plot(x, p,label=\"$\\mu$={:.2E}, $\\sigma$={:.2E}\".format(mu, std), linewidth=2,color=\"red\")\n",
    "axs[0].set_ylabel(\"Torque [N m]\")\n",
    "axs[1].set_ylabel(\"Counts\")\n",
    "axs[0].set_xticks(np.arange(lolim,uplim,step=np.timedelta64(1,\"D\")))\n",
    "axs[0].set_xlim(lolim,uplim)\n",
    "for ax in axs:\n",
    "    ax.grid()\n",
    "# axs[0].set_ylim(-0.4E5,0.4E5)\n",
    "# axs[1].set_ylim(-0.8E4,0.8E4)\n",
    "axs[1].set_xlabel(\"Date\")\n",
    "showAndClear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd74ab2a-7c7a-437e-b5c8-aa9df3783fbd",
   "metadata": {},
   "source": [
    "### M1M3 Surrogate and Cell, M2 Surrogate and Cell on the TMA - Nov 2023 to Jan 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bb53aa-7537-4c7b-b8ca-aa4e9f3fb0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "startPoint = np.datetime64(\"2023-11-01T12:00:00\")\n",
    "endPoint = np.datetime64(\"2024-01-01T12:00:00\")\n",
    "starts,ends = makeDateRange(startPoint,endPoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1d5209-bedf-4482-8dca-47678c510db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = await getDataFrame(client,starts,ends,topic,fields=fields,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b82acc2-99a6-4d72-b817-fbeb93b05881",
   "metadata": {},
   "outputs": [],
   "source": [
    "lolim,uplim = pd.Timestamp(\"2023-11-14\").tz_localize(\"UTC\"),pd.Timestamp(\"2023-11-25\").tz_localize(\"UTC\")\n",
    "limited_data = all_data.loc[lolim:uplim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dcec2f-6c03-4411-81ad-d38692001b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,1,figsize=[10,6],sharex=True)\n",
    "for ax in axs:\n",
    "    ax.plot(limited_data.index,limited_data)\n",
    "    ax.set_ylabel(\"Torque [N m]\")\n",
    "    ax.set_xticks(np.arange(lolim,uplim,step=np.timedelta64(1,\"D\")))\n",
    "    ax.set_xlim(lolim,uplim)\n",
    "    ax.grid()\n",
    "axs[0].set_ylim(-0.4E5,0.4E5)\n",
    "axs[1].set_ylim(-0.8E4,0.8E4)\n",
    "axs[1].set_xlabel(\"Date\")\n",
    "showAndClear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8ea89f-e4a1-41f6-85f0-4481a74d7e91",
   "metadata": {},
   "source": [
    "### M2 Surrogate and Cell on the TMA - Feb to Apr 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f5313e-3694-4c84-8a01-86e71f615cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "startPoint = np.datetime64(\"2024-02-01T12:00:00\")\n",
    "endPoint = np.datetime64(\"2024-04-01T12:00:00\")\n",
    "starts,ends = makeDateRange(startPoint,endPoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939a5bb7-9b2c-4dd5-8e3b-651cf6bf3805",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = await getDataFrame(client,starts,ends,topic,fields=fields,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6efe73b-a5de-4c97-917c-548e5e5b4bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lolim,uplim = pd.Timestamp(\"2024-02-05\").tz_localize(\"UTC\"),pd.Timestamp(\"2024-02-15\").tz_localize(\"UTC\")\n",
    "limited_data = all_data.loc[lolim:uplim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5871c1c3-8c6d-43c5-bb00-0a3425860088",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,1,figsize=[10,6],sharex=True)\n",
    "for ax in axs:\n",
    "    ax.plot(limited_data.index,limited_data)\n",
    "    ax.set_ylabel(\"Torque [N m]\")\n",
    "    ax.set_xticks(np.arange(lolim,uplim,step=np.timedelta64(2,\"D\")))\n",
    "    ax.set_xlim(lolim,uplim)\n",
    "    ax.grid()\n",
    "axs[0].set_ylim(-2E5,2E5)\n",
    "axs[1].set_ylim(-0.8E2,0.8E2)\n",
    "axs[1].set_xlabel(\"Date\")\n",
    "showAndClear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86545d02-590c-4043-a192-bc6149654b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a027c5f8-b56a-40a7-8323-2a9a4f95074d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
